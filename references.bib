@ARTICLE{Kim2018197,
type={CONFERENCE},
author={Kim, R. and Kleiman-Weiner, M. and Abeliuk, A. and Awad, E. and Dsouza, S. and Tenenbaum, J.B. and Rahwan, I.},
title={A Computational Model of Commonsense Moral Decision Making},
journal={AIES 2018 - Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
year={2018},
volume={NA},
pages={197-203},
doi={10.1145/3278721.3278770},
note={cited By 11; Conference of 1st AAAI/ACM Conference on AI, Ethics, and Society, AIES 2018 ; Conference Date: 2 February 2018 Through 3 February 2018;  Conference Code:144126},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061032466&doi=10.1145%2f3278721.3278770&partnerID=40&md5=1192c02592b3d7814fa82104192a599c},
affiliation={Massachusetts Institute of Technology, Cambridge, MA, United States},
abstract={We introduce a computational model for building moral autonomous vehicles by learning and generalizing from human moral judgments. We draw on a cognitively inspired model of how people and young children learn moral theories from sparse and noisy data and integrate observations made from different people in different groups. The problem of moral learning for autonomous vehicles is cast as learning how to weigh the different features of the dilemma using utility calculus, with the goal of making these trade-offs reflect how people make them in a wide variety of moral dilemma. By modeling the structures of individuals and groups in a hierarchical Bayesian model, we show that an individual's moral values - as well as a group's shared values - can be inferred from sparse and noisy data. We evaluate our approach with data from the Moral Machine, a web application that collects human judgments on moral dilemmas involving autonomous vehicles, and show that the model rapidly and accurately infers people's preferences and can predict the difficulty of moral dilemmas from limited data. Â© 2018 ACM.},
author_keywords={artificial intelligence;  Bayesian inference;  machine ethics;  moral learning},
keywords={Artificial intelligence;  Autonomous vehicles;  Bayesian networks;  Behavioral research;  Calculations;  Computational methods;  Decision making;  Economic; social effects;  Inference engines;  Philosophical aspects, Bayesian inference;  Computational model;  Hierarchical Bayesian modeling;  Human judgments;  Moral judgment;  moral learning;  WEB application;  Young children, Computation theory},
references={Baron, J., GÃ¼rÃ§ay, B., A meta-analysis of response-time tests of the sequential two-systems model of moral judgment (2017) Memory & Cognition, 45 (4), pp. 566-575. , https://doi.org/10.3758/s13421-016-0686-8, (5 2017); Bentham, J., (1789) An Introduction to the Principles of Morals and Legislation, , https://doi.org/10.1111/j.2048-416X.2000.tb00070.x; Blake, P.R., McAuliffe, K., Corbit, J., Callaghan, T.C., Barry, O., Bowie, A., Kleutsch, L., Warneken, F., The ontogeny of fairness in seven societies (2015) Nature, 528 (7581), pp. 258-261. , https://doi.org/10.1038/nature15703, (2015); Bonnefon, J., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352 (6293). , http://science.sciencemag.org/content/352/6293/1573.abstract, (6 2016), 1573 LP - 1576; Cain, N., Shea-Brown, E., (2012) Computational Models of Decision Making: Integration, Stability, and Noise, , https://doi.org/10.1016/j.conb.2012.04.013; Susan, C., (2009) The Origin of Concepts, 598p. , https://global.oup.com/academic/product/the-origin-of-concepts-9780199838806#.WfDc448zKVM.mendeley, Oxford University Press; Felbo, B., Mislove, A., SÃ¸gaard, A., Rahwan, I., Lehmann, S., Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm (2017) Conference on Empirical Methods in Natural Language Processing (EMNLP); Gelman, A., Carlin, J.B., Stern, H.S., Dunson, D.B., Vehtari, A., Rubin, D.B., (2013) Bayesian Data Analysis, Third Edition, , https://books.google.com/books?id=ZXL6AQAAQBAJ, Taylor & Francis; Goodman, B., Flaxman, S., (2016) European Union Regulations on Algorithmic Decision-making and A "right to Explanation", , http://arxiv.org/abs/1606.08813, (6 2016); Gopnik, A., Meltzoff, A.N., (1997) Words, Thoughts, and Theories, 268, p. 268. , The MIT Press, Cambridge, MA, US., xvi, xvi pages; Graham, J., Haidt, J., Nosek, B.A., Liberals and conservatives rely on different sets of moral foundations (2009) Journal of Personality and Social Psychology, , https://doi.org/10.1037/a0015141, (2009); Henrich, J., Boyd, R., Bowles, S., Camerer, C., Fehr, E., Gintis, H., McElreath, R., In search of homo economicus: Behavioral experiments in 15 small-scale societies (2001) The American Economic Review, 91 (2), pp. 73-78. , http://www.jstor.org/stable/2677736, (2001); House, B.R., Silk, J.B., Henrich, J., Clark Barrett, H., Scelza, B.A., Boyette, A.H., Hewlett, B.S., Laurence, S., Ontogeny of prosocial behavior across diverse societies (2013) Proceedings of the National Academy of Sciences, 110 (36), pp. 14586-14591. , https://doi.org/10.1073/pnas.1221217110, (2013); Kleiman-Weiner, M., Saxe, R., Tenenbaum, J.B., Learning a commonsense moral theory (2017) Cognition, 167, pp. 107-123. , https://doi.org/10.1016/j.cognition.2017.03.005, (2017); Kohlberg, L., Essays in moral development (1981) The Philosophy of Moral Development; Lei, T., Barzilay, R., Jaakkola, T., (2016) Rationalizing Neural Predictions, , http://arxiv.org/abs/1606.04155, (6 2016); Lewandowski, D., Kurowicka, D., Joe, H., Generating random correlation matrices based on vines and extended onion method (2009) Journal of Multivariate Analysis, 100 (9), pp. 1989-2001. , https://doi.org/10.1016/j.jmva.2009.04.008, (2009); Mikhail, J., Universal moral grammar: Theory, evidence and the future (2007) Trends in Cognitive Sciences, 11 (4), pp. 143-152. , https://doi.org/10.1016/j.tics.2006.12.007, (2007); Mikhail, J., (2011) Elements of Moral Cognition, , https://doi.org/10.1017/CBO9780511780578, Cambridge University Press, Cambridge; Noothigattu, R., Gaikwad, S.N.S., Awad, E., Dsouza, S., Rahwan, I., Ravikumar, P., Procaccia, A.D., (2017) A Voting-Based System for Ethical Decision Making, , http://arxiv.org/abs/1709.06692, (9 2017); Van-Den-Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Kavukcuoglu, K., (2016) WaveNet: A Generative Model for Raw Audio, pp. 1-15. , http://arxiv.org/abs/1609.03499, (2016); Rai, P., Hal Daume, The infinite hierarchical factor regression model (2009) Advances in Neural Information Processing Systems 21, pp. 1321-1328. , http://arxiv.org/abs/0908.0570, (2009); Ratcliff, R., McKoon, G., The diffusion decision model: Theory and data for two-choice decision tasks (2008) Neural Computation, 20 (4), pp. 873-922. , https://doi.org/10.1162/neco.2008.12-06-420, (4 2008); Santoro, A., Bartunov, S., Botvinick, M., Wierstra, D., Lillicrap, T., (2016) One-shot Learning with Memory-Augmented Neural Networks, , http://arxiv.org/abs/1605.06065, (5 2016); Smith, P.L., Ratcliff, R., Psychology and neurobiology of simple decisions (2004) Trends in Neurosciences, , https://doi.org/10.1016/j.tins.2004.01.006, (2004); Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going Deeper with Convolutions, , [n. d.]. ([n. d.]); Tenenbaum, J.B., Kemp, C., Griffiths, T.L., Goodman, N.D., Howto growa mind: Statistics, structure, and abstraction (2011) Science, 331 (6022), p. 1279. , http://science.sciencemag.org/content/331/6022/1279.abstract, (3 2011); Ghahramani, Z., Griffiths, T.L., Infinite latent feature models and the Indian buffet process (2005) Advances in Neural Information Processing Systems 18, pp. 475-482. , http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.60.3951, (2005); Vinyals, O., Blundell, C., Lillicrap, T., Kavukcuoglu, K., Wierstra, D., (2016) Matching Networks for One Shot Learning, , http://arxiv.org/abs/1606.04080, (6 2016); Wu, Y., Schuster, M., Chen, Z., Le, Q.V., Norouzi, M., Macherey, W., Krikun, M., Dean, J., (2016) Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation, , http://arxiv.org/abs/1609.08144, (9 2016)},
correspondence_address1={NA},
editor={NA},
publisher={Association for Computing Machinery, Inc},
issn={NA},
isbn={9781450360128},
language={English},
abbrev_source_title={AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
document_type={Conference Paper},
source={Scopus},
number={NA},
art_number={NA},
funding_details={NA},
coden={NA},
pubmed_id={NA},
sponsors={AAAI; ACM SIGAI},
address={NA},
screened_abstracts={selected},
notes={NA},
}

@ARTICLE{Awad201859,
type={ARTICLE},
author={Awad, E. and Dsouza, S. and Kim, R. and Schulz, J. and Henrich, J. and Shariff, A. and Bonnefon, J.-F. and Rahwan, I.},
title={The Moral Machine experiment},
journal={Nature},
year={2018},
volume={563},
pages={59-64},
doi={10.1038/s41586-018-0637-6},
note={cited By 457},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055831155&doi=10.1038%2fs41586-018-0637-6&partnerID=40&md5=de8fa111ffddea46578f643a6f47529c},
affiliation={The Media Lab, Massachusetts Institute of Technology, Cambridge, MA, United States; Department of Human Evolutionary Biology, Harvard University, Cambridge, MA, United States; Department of Psychology, University of British Columbia, Vancouver, BC, Canada; Toulouse School of Economics (TSM-R), CNRS, UniversitÃ© Toulouse Capitole, Toulouse, France; Institute for Data, Systems & Society, Massachusetts Institute of Technology, Cambridge, MA, United States},
abstract={With the rapid development of artificial intelligence have come concerns about how machines will make moral decisions, and the major challenge of quantifying societal expectations about the ethical principles that should guide machine behaviour. To address this challenge, we deployed the Moral Machine, an online experimental platform designed to explore the moral dilemmas faced by autonomous vehicles. This platform gathered 40 million decisions in ten languages from millions of people in 233 countries and territories. Here we describe the results of this experiment. First, we summarize global moral preferences. Second, we document individual variations in preferences, based on respondentsâ€™ demographics. Third, we report cross-cultural ethical variation, and uncover three major clusters of countries. Fourth, we show that these differences correlate with modern institutions and deep cultural traits. We discuss how these preferences can contribute to developing global, socially acceptable principles for machine ethics. All data used in this article are publicly available. Â© 2018, Springer Nature Limited.},
author_keywords={NA},
keywords={adult;  article;  ethics;  human;  language;  machine;  morality;  artificial intelligence;  decision making;  ethics;  female;  harm reduction;  information processing;  international cooperation;  Internet;  male;  motor vehicle;  pedestrian;  procedures;  public opinion;  robotics;  traffic accident;  translating (language), Accidents, Traffic;  Artificial Intelligence;  Data Collection;  Decision Making;  Female;  Harm Reduction;  Humans;  Internationality;  Internet;  Male;  Morals;  Motor Vehicles;  Pedestrians;  Public Opinion;  Robotics;  Translating},
references={Greene, J., (2013) Moral Tribes: Emotion, Reason and the Gap between Us and Them, , Atlantic Books, London; Tomasello, M.A., (2014) Natural History of Human Thinking, , Harvard Univ. Press, Cambridge; Cushman, F., Young, L., The psychology of dilemmas and the philosophy of morality (2009) Ethical Theory Moral Pract., 12, pp. 9-24; Asimov, I.I., (1950) Robot, , Doubleday, New York; Bryson, J., Winfield, A., Standardizing ethical design for artificial intelligence and autonomous systems (2017) Computer, 50, pp. 116-119; Wiener, N., Some moral and technical consequences of automation (1960) Science, 131, pp. 1355-1358. , COI: 1:STN:280:DC%2BC3cvmtFSqtw%3D%3D; Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , Oxford Univ. Press, Oxford; Responsible autonomy (2017) Proc. 26Th International Joint Conference on Artificial Intelligence 4698â€“4704 (IJCAI; Dadich, S., (2016) Barack Obama, Neural Nets, Self-Driving Cars, and the Future of the World, , https://www.wired.com/2016/10/president-obama-mit-joi-ito-interview/, Wired; Shariff, A., Bonnefon, J.-F., Rahwan, I., Psychological roadblocks to the adoption of self-driving vehicles (2017) Nat. Hum. Behav., 1, pp. 694-696; Conitzer, V., Brill, M., Freeman, R., Crowdsourcing societal tradeoffs (2015) Proc. 2015 International Conference on Autonomous Agents and Multiagent Systems, pp. 1213-1217. , IFAAMAS; Bonnefon, J.-F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352, pp. 1573-1576. , COI: 1:CAS:528:DC%2BC28XhtVaitLzK; Hauser, M., Cushman, F., Young, L., Jin, K.-X.R., Mikhail, J., A dissociation between moral judgments and justifications (2007) Mind Lang., 22, pp. 1-21; Carlsson, F., Daruvala, D., Jaldell, H., Preferences for lives, injuries, and age: a stated preference survey (2010) Accid. Anal. Prev., 42, pp. 1814-1821; Johansson-Stenman, O., Martinsson, P., Are some lives more valuable? An ethical preferences approach (2008) J. Health Econ., 27, pp. 739-752; Johansson-Stenman, O., Mahmud, M., Martinsson, P., Saving lives versus life-years in rural Bangladesh: an ethical preferences approach (2011) Health Econ., 20, pp. 723-736; Graham, J., Meindl, P., Beall, E., Johnson, K.M., Zhang, L., Cultural differences in moral judgment and behavior, across and within societies (2016) Current Opinion in Psychology, 8, pp. 125-130; Hainmueller, J., Hopkins, D.J., Yamamoto, T., Causal inference in conjoint analysis: understanding multidimensional choices via stated preference experiments (2014) Polit. Anal., 22, pp. 1-30; Luetge, C., The German Ethics Code for automated and connected driving (2017) Philos. Technol., 30, pp. 547-558; MÃ¼llner, D., (2011) Modern Hierarchical, Agglomerative Clustering Algorithms, , https://arxiv.org/abs/1109.2378, Preprint at; Inglehart, R., Welzel, C., (2005) Modernization, Cultural Change, and Democracy: The Human Development Sequence, , Cambridge Univ. Press, Cambridge; Muthukrishna, M., (2018) Beyond WEIRD Psychology: Measuring and Mapping Scales of Cultural and Psychological Distance, , https://ssrn.com/abstract=3259613, Preprint at; Hofstede, G., (2003) Cultureâ€™s Consequences: Comparing Values, Behaviors, Institutions and Organizations across Nations, , Sage, Thousand Oaks; (2017) World Economic Outlook Database, , https://www.imf.org/external/pubs/ft/weo/2017/01/weodata/index.aspx; Kaufmann, D., Kraay, A., Mastruzzi, M., The worldwide governance indicators: methodology and analytical issues (2011) Hague J. Rule Law, 3, pp. 220-246; GÃ¤chter, S., Schulz, J.F., Intrinsic honesty and the prevalence of rule violations across societies (2016) Nature, 531, pp. 496-499; Oâ€™Neil, C., (2016) Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy, , Penguin, London; Henrich, J., In search of Homo Economicus: behavioral experiments in 15 small-scale societies (2001) Am. Econ. Rev., 91, pp. 73-78; (2017) Future of Life Institute. Asilomar AI Principles, , https://futureoflife.org/ai-principles/; Haidt, J., (2012) The Righteous Mind: Why Good People are Divided by Politics and Religion, , Knopf Doubleday, New York; Gastil, J., Braman, D., Kahan, D., Slovic, P., The cultural orientation of mass political opinion (2011) PS Polit. Sci. Polit., 44, pp. 711-714; Nishi, A., Christakis, N.A., Rand, D.G., Cooperation, decision time, and culture: online experiments with American and Indian participants (2017) PLoS One, 12},
correspondence_address1={Rahwan, I.; The Media Lab, United States; email: irahwan@mit.edu},
editor={NA},
publisher={Nature Publishing Group},
issn={00280836},
isbn={NA},
language={English},
abbrev_source_title={Nature},
document_type={Article},
source={Scopus},
number={7729},
art_number={NA},
funding_details={NA},
coden={NATUA},
pubmed_id={30356211},
sponsors={NA},
address={NA},
screened_abstracts={selected},
notes={NA},
}


@incollection{GRAHAM201355,
title = {Chapter Two - Moral Foundations Theory: The Pragmatic Validity of Moral Pluralism},
editor = {Patricia Devine and Ashby Plant},
series = {Advances in Experimental Social Psychology},
publisher = {Academic Press},
volume = {47},
pages = {55-130},
year = {2013},
issn = {0065-2601},
doi = {https://doi.org/10.1016/B978-0-12-407236-7.00002-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780124072367000024},
author = {Jesse Graham and Jonathan Haidt and Sena Koleva and Matt Motyl and Ravi Iyer and Sean P. Wojcik and Peter H. Ditto},
keywords = {Morality, Nativism, Cultural learning, Intuition, Pluralism, Method-theory coevolution},
abstract = {Where does morality come from? Why are moral judgments often so similar across cultures, yet sometimes so variable? Is morality one thing, or many? Moral Foundations Theory (MFT) was created to answer these questions. In this chapter, we describe the origins, assumptions, and current conceptualization of the theory and detail the empirical findings that MFT has made possible, both within social psychology and beyond. Looking toward the future, we embrace several critiques of the theory and specify five criteria for determining what should be considered a foundation of human morality. Finally, we suggest a variety of future directions for MFT and moral psychology.}
}

@article{vanWynsberghe2019719,
type={ARTICLE},
author={van Wynsberghe, A. and Robbins, S.},
title={Critiquing the Reasons for Making Artificial Moral Agents},
journal={Science and Engineering Ethics},
year={2019},
volume={25},
pages={719-735},
doi={10.1007/s11948-018-0030-8},
note={cited By 44},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042189041&doi=10.1007%2fs11948-018-0030-8&partnerID=40&md5=f2cc175e33498f68f690a39f3664bf7c},
affiliation={Technical University of Delft, Jaffalaan 5, Delft, 2628 BX, Netherlands},
abstract={Many industry leaders and academics from the field of machine ethics would have us believe that the inevitability of robots coming to have a larger role in our lives demands that robots be endowed with moral reasoning capabilities. Robots endowed in this way may be referred to as artificial moral agents (AMA). Reasons often given for developing AMAs are: the prevention of harm, the necessity for public trust, the prevention of immoral use, such machines are better moral reasoners than humans, and building these machines would lead to a better understanding of human morality. Although some scholars have challenged the very initiative to develop AMAs, what is currently missing from the debate is a closer examination of the reasons offered by machine ethicists to justify the development of AMAs. This closer examination is especially needed because of the amount of funding currently being allocated to the development of AMAs (from funders like Elon Musk) coupled with the amount of attention researchers and industry leaders receive in the media for their efforts in this direction. The stakes in this debate are high because moral robots would make demands on society; answers to a host of pending questions about what counts as an AMA and whether they are morally responsible for their behavior or not. This paper shifts the burden of proof back to the machine ethicists demanding that they give good reasons to build AMAs. The paper argues that until this is done, the development of commercially available AMAs should not proceed further. Â© 2018, The Author(s).},
author_keywords={Artificial moral agents;  Machine ethics;  Robot ethics},
keywords={artificial intelligence;  ethicist;  ethics;  morality;  robotics, Artificial Intelligence;  Ethical Analysis;  Ethicists;  Moral Development;  Morals;  Robotics},
references={Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7 (3), pp. 149-155; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental & Theoretical Artificial Intelligence, 12 (3), pp. 251-261; Allen, C., Wallach, W., Moral machines: Contradition in terms of abdication of human responsibility? (2011) Robot ethics: The ethical and social implications of robotics, pp. 55-68. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intelligent Systems, 21 (4), pp. 12-17; Anderson, S.L., Machine metaethics (2011) Machine Ethics, , M. Anderson, S. L. Anderson, New York, Cambridge University Press; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26; Anderson, M., Anderson, S.L., Robot be good: A call for ethical autonomous machines (2010) Scientific American, 303 (4), pp. 15-24; Anderson, M., Anderson, S.L., (2011) Machine ethics, , Cambridge University Press, Cambridge; (1998) The Nicomachean ethics, , http://books.google.nl/books?id=Dk2VFlZyiJQC, Oxford University Press. Retrieved from, Accessed 24 Oct 2014; Arkin, R., (2009) Governing lethal behavior in autonomous robots, , CRC Press, Boca Raton; Asimov, I., (1963) I, Robot, , Spectra, New York; Baier, A., Trust and antitrust (1986) Ethics, 96 (2), pp. 231-260; Bryson, J., Robots should be slaves (2008) Close Engagements with Artificial Companions: Key Social, Psychological, Ethical and Design Issue, pp. 63-74. , https://books.google.nl/books?id=EPznZHeG89cC, In Y. Wilks (Ed.), Amsterdam: John Benjamins Publishing. Retrieved from, Accessed 7 Mar 2017; Cellan-Jones, R., Stephen Hawking warns artificial intelligence could end mankind (2014) BBC News, , http://www.bbc.com/news/technology-30290540.Accessed29Aug2016, Retrieved from; Coeckelbergh, M., Robot rights? Towards a social-relational justification of moral consideration (2010) Ethics and Information Technology, 12 (3), pp. 209-221; Darling, K., (2012) Extending Legal Protection to Social Robots: The Effects of Anthropomorphism, Empathy, and Violent Behavior Towards Robotic Objects, , https://papers.ssrn.com/abstract=2044797, Rochester, NY, Retrieved from; Deng, B., Machine ethics: The robotâ€™s dilemma (2015) Nature News, 523 (7558), p. 24; Dietrich, E., Homo sapiens 2.0: Why we should build the better robots of our nature (2001) Journal of Experimental & Theoretical Artificial Intelligence, 13 (4), pp. 323-328; Doris, J.M., Persons, situations, and virtue ethics (1998) Nous, 32 (4), pp. 504-530. , http://www.jstor.org/stable/pdfplus/2671873.pdf?acceptTC=true, (,).,., (,)., Retrieved from; Finlay, S., Four faces of moral realism (2007) Philosophy Compass, 2 (6), pp. 820-849; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds and Machines, 14 (3), pp. 349-379; Friedman, B., Nissenbaum, H., Bias in computer systems (1996) ACM Transactions on Information Systems, 14 (3), pp. 330-347. , https://doi.org/10.1145/230538.230561, Retrieved 10 Feb 2017; Gershgorn, D., (2017) Inside the Mechanical Brain of the worldâ€™s First Robot Citizen, , https://qz.com/1121547/how-smart-is-the-first-robot-citizen/, Retrieved 29 Dec 2017; Gips, J., Toward the ethical robot (1994) Android Epistemology, , K. M. Ford, C. Glymour, P. Hayes, Cambridge, MIT Press; Greene, J., (2013) Moral tribes: Emotion, reason, and the gap between us and them, , 1, Penguin Press, New York; Gunkel, D.J., A vindication of the rights of machines (2014) Philosophy & Technology, 27 (1), pp. 113-132; Haidt, J., The emotional dog and its rational tail: A social intuitionist approach to moral judgment (2001) Psychological Review, 108 (4), pp. 814-834; Haidt, J., Joseph, C., The Innate Mind: Volume 3: Foundations and the Future (Evolution and Cognition) (2008) The innate mind, , Carruthers P, Laurence S, Stich S, (eds), Oxford University Press, New York; Hardwig, J., The role of trust in knowledge (1991) The Journal of Philosophy, 88 (12), pp. 693-708; Hatmaker, T., (2017) Saudi Arabia Bestows Citizenship on a Robot Named Sophia, , http://social.techcrunch.com/2017/10/26/saudi-arabia-robot-citizen-sophia/, Retrieved 12 Feb 2018; Himma, K.E., Artificial agency, consciousness, and the criteria for moral agency: What properties must an artificial agent have to be a moral agent? (2009) Ethics and Information Technology, 11 (1), pp. 19-29; Johnson, D.G., Miller, K.W., Un-making artificial moral agents (2008) Ethics and Information Technology, 10 (2-3), pp. 123-133; KristjÃ¡nsson, K., Emulation and the use of role models in moral education (2006) Journal of Moral Education, 35 (1), pp. 37-49. , http://www.tandfonline.com/doi/abs/10.1080/03057240500495278, Retrieved from, Accessed 25 Oct 2014; Lokhorst, G.-J., van den Hoven, J., Responsibility for Military Robots (2011) Robot ethics: The ethical and social implications of robotics, pp. 145-155. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; Markoff, J., Relax, the terminator is far away (2015) The New York Times, , http://www.nytimes.com/2015/05/26/science/darpa-robotics-challenge-terminator.html, Retrieved from, Accessed 29 Aug 2016; Merritt, M., Virtue ethics and situationist personality psychology (2000) Ethical Theory and Moral Practice, 3 (4), pp. 365-383; Miller, K.W., Wolf, M.J., Grodzinsky, F., This â€œethical trapâ€ is for roboticists, not robots: on the issue of artificial agent ethical decision-making (2017) Science and Engineering Ethics, 23 (2), pp. 389-401; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Moor, J., Four kinds of ethical robots (2009) Philosophy Now, (72), pp. 12-14. , https://philosophynow.org/issues/72/Four_Kinds_of_Ethical_Robots, Retrieved from, Accessed 10 Feb 2017; (2012) The Economist, , http://www.economist.com/node/21556234, Retrieved from, Accessed 7 Mar 2017; Nagenborg, M., Artificial moral agents: An intercultural perspective (2007) International Review of Information Ethics, 7, pp. 129-133. , http://www.i-r-i-e.net/inhalt/007/13-nagenborg.pdf, Retrieved 12 Feb 2018; Nissenbaum, H., How computer systems embody values (2001) Computer -Los Almalitos-, 34, p. 120; Peters, A., Having a heart attack? (2018) This AI Helps Emergency Dispatchers Find Out, , https://www.fastcompany.com/40515740/having-a-heart-attack-this-ai-helps-emergency-dispatchers-find-out, Retrieved January 16, 2018, from; Pizarro, D., Nothing More than Feelings? The Role of Emotions in Moral Judgment (2000) Journal for the Theory of Social Behaviour, 30 (4), pp. 355-375; Roeser, S., (2010) Moral emotions and intuitions, , Springer, Berlin; Rutkin, A., (2014) Ethical Trap: Robot Paralysed by Choice of Who to Save, , https://www.newscientist.com/article/mg22329863-700-ethical-trap-robot-paralysed-by-choice-of-who-to-save/, Retrieved 12 Feb 2018; Scheutz, M., (2016) The need for moral competency in autonomous agent architectures, pp. 515-525. , http://link.springer.com/chapter/10.1007/978-3-319-26485-1_30, In V. C. MÃ¼ller (Ed.), Springer International Publishing. Retrieved from, Accessed 29 Aug 2016; Shafer-Landau, R., Ethical disagreement, ethical objectivism and moral indeterminacy (1994) Philosophy and Phenomenological Research, 54 (2), pp. 331-344; Sharkey, A., Should we welcome robot teachers? (2016) Ethics and Information Technology; Sharkey, A., Can robots be responsible moral agents? And why should we care? (2017) Connection Science, 29 (3), pp. 210-216; Sharkey, N., The ethical frontiers of robotics (2008) Science, 322 (5909), pp. 1800-1801; Sharkey, N., The evitability of autonomous robot warfare (2012) International Review of the Red Cross, 94 (886), pp. 787-799; Sharkey, N., Sharkey, A., The Rights and Wrongs of Robot Care (2011) Robot ethics: The ethical and social implications of robotics, pp. 267-282. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; Sharkey, N., Wynsberghe, A., Robbins, S., Hancock, E., (2017) Our Sexual Future with Robots, , https://responsible-roboticsmyxf6pn3xr.netdna-ssl.com/wp-content/uploads/2017/11/FRR-Consultation-Report-Our-Sexual-Future-with-robots-.pdf, The Hague, Netherlands, Retrieved from, Accessed 1 Feb 2018; Shirky, C., (2009) A Speculative Post on the Idea of Algorithmic Authority, , http://www.shirky.com/weblog/2009/11/a-speculative-post-on-the-idea-of-algorithmic-authority/, Retrieved 12 Feb 2018; Simon, J., The entanglement of trust and knowledge on the Web (2010) Ethics and Information Technology, 12 (4), pp. 343-355; Street, S., A darwinian dilemma for realist theories of value (2006) Philosophical Studies, 127 (1), pp. 109-166; Tonkens, R., A challenge for machine ethics (2009) Minds and Machines, 19 (3), pp. 421-438; Vallor, S., Moral deskilling and upskilling in a new machine age: Reflections on the ambiguous future of character (2015) Philosophy & Technology, 28 (1), pp. 107-124; van de Poel, I., Translating Values into design requirements (2013) Philosophy and engineering: Reflections on practice, principles, and process, , Mitchfelder D, McCarty N, Goldberg DE, (eds), Springer, Dordrecht; van den Hoven, J., ICT and value sensitive design (2007) The information society: Innovation, legitimacy, ethics and democracy in honor of professor Jacques Berleur s.j, 233, pp. 67-72. , Goujon P, Lavelle S, Duquenoy P, Kimppa K, (eds), Springer, Boston; van Wynsberghe, A., Designing robots for care: Care centered value-sensitive design (2012) Science and Engineering Ethics, 19 (2), pp. 407-433; van Wynsberghe, A., A method for integrating ethics into the design of robots (2013) Industrial Robot: An International Journal, 40 (5), pp. 433-440; van Wynsberghe, A., (2015) Healthcare Robots: Ethics, Design and Implementation. Healthcare Robots: Ethics, Design and Implementation, , https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946412196&partnerID=40&md5=5c270c5c2c8d9f4983cbe6c4f2369c97, Retrieved from, Accessed 29 Aug 2016; van Wynsberghe, A., Service robots, care ethics, and design (2016) Ethics and Information Technology, 18 (4), pp. 311-321; van Wynsberghe, A., Robbins, S., Ethicist as designer: A pragmatic approach to ethics in the lab (2014) Science and Engineering Ethics, 20 (4), pp. 947-961. , https://doi.org/10.1007/s11948-013-9498-4; Waldrop, M.M., A question of responsibility (1987) AI Magazine, 8 (1), p. 28; Wallach, W., Implementing moral decision making faculties in computers and robots (2007) AI & Society, 22 (4), pp. 463-475; Wallach, W., Robot minds and human ethics: The need for a comprehensive model of moral decision making (2010) Ethics and Information Technology, 12 (3), pp. 243-250; Wallach, W., Allen, C., (2010) Moral Machines: Teaching Robots Right from Wrong, , https://www.amazon.com/Moral-Machines-Teaching-Robots-Right/dp/0199737975, New York, Oxford University Press, Retrieved from, Accessed 10 Feb 2017; Wiegel, V., Building blocks for artificial moral agents (2006) Proceedings of Ethicalalife06 Workshop, , https://www.researchgate.net/profile/Vincent_Wiegel/publication/228615030_Building_blocks_for_artificial_moral_agents/links/55fabe5708aeafc8ac3fe6f8/Buildingblocks-for-artificial-moral-agents.pdf, Retrieved 12 Feb 2018; Wiegel, V., Wendell Wallach and Colin Allen: Moral machines: Teaching robots right from wrong (2010) Ethics and Information Technology, 12 (4), pp. 359-361},
correspondence_address1={van Wynsberghe, A.; Technical University of Delft, Jaffalaan 5, Netherlands; email: aimeevanrobot@gmail.com},
editor={NA},
publisher={Springer Netherlands},
issn={13533452},
isbn={NA},
language={English},
abbrev_source_title={Sci. Eng. Ethics},
document_type={Article},
source={Scopus},
number={3},
art_number={NA},
funding_details={Horizon 2020 Framework ProgrammeHorizon 2020 Framework Programme,Â H2020},
coden={NA},
pubmed_id={29460081},
sponsors={NA},
address={NA},
screened_abstracts={selected},
notes={NA},
}


@misc{Industri87:online,
author = {Fortune},
title = {Industrial Automation Market Size, Share | Growth Report [2029]},
howpublished = {\url{https://www.fortunebusinessinsights.com/industry-reports/industrial-automation-market-101589}},
month = {},
year = {2022},
note = {(Accessed on 07/02/2022)}
}

@article{rotaru2021precise,
  title={Precise Event-level Prediction of Urban Crime Reveals Signature of Enforcement Bias},
  author={Rotaru, Victor and Huang, Yi and Li, Timmy and Evans, James and Chattopadhyay, Ishanu},
  year={2021}
}

@misc{Amazon:online,
author = {Jay Greene},
title = {Amazon monitors its warehouse staff, leading to unionization efforts - The Washington Post},
howpublished = {\url{https://www.washingtonpost.com/technology/2021/12/02/amazon-workplace-monitoring-unions/}},
month = {December},
year = {2021},
note = {(Accessed on 07/02/2022)}
}

@misc{jef:online,
author = {Jack Kelly},
title = {A Hard-Hitting Investigative Report Into Amazon Shows That Workers’ Needs Were Neglected In Favor Of Getting Goods Delivered Quickly},
howpublished = {\url{https://www.forbes.com/sites/jackkelly/2021/10/25/a-hard-hitting-investigative-report-into-amazon-shows-that-workers-needs-were-neglected-in-favor-of-getting-goods-delivered-quickly/?sh=27b0270551f5}},
month = {October},
year = {2021},
note = {(Accessed on 07/02/2022)}
}

@ARTICLE{Telkamp2022,
type={ARTICLE},
author={Telkamp, J.B. and Anderson, M.H.},
title={The Implications of Diverse Human Moral Foundations for Assessing the Ethicality of Artificial Intelligence},
journal={Journal of Business Ethics},
year={2022},
volume={NA},
pages={NA},
doi={10.1007/s10551-022-05057-6},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124730522&doi=10.1007%2fs10551-022-05057-6&partnerID=40&md5=919d2ebdae744cd9f91f178cd6c6b22c},
affiliation={Department of Management and Entrepreneurship, Ivy College of Business, Steve and Becky Smith Management and Marketing Suite, Iowa State University, 2350 Gerdin Business Building, 2167 Union Drive, Ames, IA  50011-2027, United States},
abstract={Organizations are making massive investments in artificial intelligence (AI), and recent demonstrations and achievements highlight the immense potential for AI to improve organizational and human welfare. Yet realizing the potential of AI necessitates a better understanding of the various ethical issues involved with deciding to use AI, training and maintaining it, and allowing it to make decisions that have moral consequences. People want organizations using AI and the AI systems themselves to behave ethically, but ethical behavior means different things to different people, and many ethical dilemmas require trade-offs such that no course of action is universally considered ethical. How should organizations using AIâ€”and the AI itselfâ€”process ethical dilemmas where humans disagree on the morally right course of action? Though a variety of ethical AI frameworks have been suggested, these approaches do not adequately address how people make ethical evaluations of AI systems or how to incorporate the fundamental disagreements people have regarding what is and is not ethical behavior. Drawing on moral foundations theory, we theorize that a person will perceive an organizationâ€™s use of AI, its data procedures, and the resulting AI decisions as ethical to the extent that those decisions resonate with the personâ€™s moral foundations. Since people hold diverse moral foundations, this highlights the crucial need to consider individual moral differences at multiple levels of AI. We discuss several unresolved issues and suggest potential approaches (such as moral reframing) for thinking about conflicts in moral judgments concerning AI. Â© 2022, The Author(s), under exclusive licence to Springer Nature B.V.},
author_keywords={Artificial intelligence;  Ethical AI frameworks;  Moral foundations;  Moral judgment},
keywords={NA},
references={Atari, M., Graham, J., Dehghani, M., Foundations of morality in Iran (2020) Evolution and Human Behavior, 41 (5), pp. 367-384; Awad, E., Dsouza, S., Kim, R., Schulz, J., Henrich, J., Shariff, A., Bonnefon, J.-F., Rahwan, I., The moral machine experiment (2018) Nature, 563 (7729), pp. 59-64; (2020), https://behavioralscientist.org/why-we-should-crowdsource-ai-ethics-and-how-to-do-so-responsibly/, Levine, S, (, September 7), Why we should crowdsource AI ethics (and how to do so responsibly). Behavioral Scientist. Retrieved from; Badaracco, J.L., Jr., (1997) Defining moments: When managers must choose between right and right, , Harvard Business School Press; Bongard, A., Automating talent acquisition: Smart recruitment, predictive hiring algorithms, and the data-driven nature of artificial intelligence (2019) Psychosociological Issues in Human Resource Management, 7 (1), pp. 36-41; Booth, R., (2019) UK Businesses Using Artificial Intelligence to Monitor Staff Activity. the Guardian, , https://www.theguardian.com/technology/2019/apr/07/uk-businesses-using-artifical-intelligence-to-monitor-staff-activity, April 7, Retrieved from; Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Winter, C., (2020) Language Models are Few-Shot Learners, , http://arxiv.org/abs/2005.14165, ArXiv, Retrieved from; Clifford, S., Iyengar, V., Cabeza, R., Sinnott-Armstrong, W., Moral foundations vignettes: A standardized stimulus database of scenarios based on moral foundations theory (2015) Behavior Research Methods, 47 (4), pp. 1178-1198; Cook, W., Kuhn, K.M., Off-duty deviance in the eye of the beholder: Implications of moral foundations theory in the age of social media (2021) Journal of Business Ethics, 172 (3), pp. 605-620; Crone, D.L., Laham, S.M., Multiple moral foundations predict responses to sacrificial dilemmas (2015) Personality and Individual Differences, 85, pp. 60-65; Cutter, C., Your next job interview may be with a robot (2018) Wall Street Journal, , https://www.wsj.com/articles/its-time-for-your-job-interview-youll-be-talking-to-yourself-1543418495, November 28, Retrieved from; Dastin, J., (2018) Amazon Scraps Secret AI Recruiting Tool that Showed Bias against Women. Reuters, , https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G, October 10, Retrieved from; DoÄŸruyol, B., Alper, S., Yilmaz, O., The five-factor model of the moral foundations theory is stable across WEIRD and non-WEIRD cultures (2019) Personality and Individual Differences, 151, p. 109547; Donaldson, T., Dunfee, T.W., Toward a unified conception of business ethics: Integrative social contracts theory (1994) Academy of Management Review, 19 (2), pp. 252-284; Egorov, M., Kalshoven, K., Pircher Verdorfer, A., Peus, C., Itâ€™s a match: Moralization and the effects of moral foundations congruence on ethical and unethical leadership perception (2020) Journal of Business Ethics, 167 (4), pp. 707-723; Etzioni, A., Moral dialogues (2018) Happiness is the wrong metric: A liberal communitarian response to populism, pp. 65-86. , Etzioni A, (ed), Springer; Fehr, R., Yam, K.C., Dang, C., Moralized leadership: The construction and consequences of ethical leader perceptions (2015) Academy of Management Review, 40 (2), pp. 182-209; Feinberg, M., Willer, R., The moral roots of environmental attitudes (2013) Psychological Science, 24 (1), pp. 56-62; Feinberg, M., Willer, R., Moral reframing: A technique for effective and persuasive communication across political divides (2019) Social and Personality Psychology Compass, 13 (12); Floridi, L., Cowls, J., A unified framework of five principles for AI in society (2019) Harvard Data Science Review; Floridi, L., Cowls, J., Beltrametti, M., Chatila, R., Chazerand, P., Dignum, V., Luetge, C., Vayena, E., AI4peopleâ€”An ethical framework for a good AI society: Opportunities, risks, principles, and recommendations (2018) Minds and Machines, 28 (4), pp. 689-707; Freeman, R.E., (1984) Strategic management: A stakeholder approach, , Pitman; Frey, B.S., Homberg, F., Osterloh, M., Organizational control systems and pay-for-performance in the public service (2013) Organization Studies, 34 (7), pp. 949-972; Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J.W., Wallach, H., DaumÃ©, I.I.I.H., Crawford, K., (2020) Datasheets for Datasets, , http://arxiv.org/abs/1803.09010, ArXiv, Retrieved from; Gilligan, C., (1982) In a different voice, , Harvard University Press; Gioia, D.A., Pinto fires and personal ethics: A script analysis of missed opportunities (1992) Journal of Business Ethics, 11 (5), pp. 379-389; Glikson, E., Woolley, A.W., Human trust in artificial intelligence: Review of empirical research (2020) Academy of Management Annals, 14 (2), pp. 627-660; Goodwin, D.K., (2005) Team of rivals: The political genius of Abraham Lincoln, , Simon and Schuster; Graham, J., Haidt, J., Koleva, S., Motyl, M., Iyer, R., Wojcik, S.P., Ditto, P.H., Moral foundations theory: The pragmatic validity of moral pluralism (2013) Advances in Experimental Social Psychology, 47, pp. 55-130; Graham, J., Haidt, J., Motyl, M., Meindl, P., Iskiwitch, C., Mooijman, M., Moral foundations theory: On the advantages of moral pluralism over moral monism (2018) Atlas of moral psychology, pp. 211-222. , Gray K, Graham J, (eds), The Guilford Press; Graham, J., Haidt, J., Nosek, B.A., Liberals and conservatives rely on different sets of moral foundations (2009) Journal of Personality and Social Psychology, 96 (5), pp. 1029-1046; Graham, J., Nosek, B.A., Haidt, J., Iyer, R., Koleva, S., Ditto, P.H., Mapping the moral domain (2011) Journal of Personality and Social Psychology, 101 (2), pp. 366-385; Hagendorff, T., The ethics of AI ethics: An evaluation of guidelines (2020) Minds and Machines, 30 (1), pp. 99-120; Haidt, J., The emotional dog and its rational tail: A social intuitionist approach to moral judgment (2001) Psychological Review, 108 (4), pp. 814-834; Haidt, J., (2012) The righteous mind: Why good people are divided by politics and religion, , Penguin; Haidt, J., Graham, J., When morality opposes justice: Conservatives have moral intuitions that liberals may not recognize (2007) Social Justice Research, 20 (1), pp. 98-116; Haidt, J., Joseph, C., Intuitive ethics: How innately prepared intuitions generate culturally variable virtues (2004) Daedalus, 133 (4), pp. 55-66; Henrich, J., Heine, S.J., Norenzayan, A., The weirdest people in the world? (2010) Behavioral and Brain Sciences, 33 (2-3), pp. 61-83; Hobbes, T., (1968) Leviathan. Penguin Books; Huang, M.H., Rust, R., Maksimovic, V., The feeling economy: Managing in the next generation of artificial intelligence (AI) (2019) California Management Review, 61 (4), pp. 43-65; Iyer, R., Koleva, S., Graham, J., Ditto, P., Haidt, J., Understanding libertarian morality: The psychological dispositions of self-identified libertarians (2012) PLoS ONE, 7 (8); Jobin, A., Ienca, M., Vayena, E., The global landscape of AI ethics guidelines (2019) Nature Machine Intelligence, 1 (9), pp. 389-399; Kaplan, A., Haenlein, M., Siri, Siri, in my hand: Whoâ€™s the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence (2019) Business Horizons, 62 (1), pp. 15-25; Kaplan, A., Haenlein, M., Rulers of the world, unite! The challenges and opportunities of artificial intelligence (2020) Business Horizons, 63 (1), pp. 37-50; Kellogg, K.C., Valentine, M.A., Christin, A., Algorithms at work: The new contested terrain of control (2020) Academy of Management Annals, 14 (1), pp. 366-410; Kohlberg, L., (1969) Stage and sequence: The cognitive-developmental approach to socialization, , Rand McNally; Kohlberg, L., From is to ought: How to commit the naturalistic fallacy and get away with it in the study of moral development (1971) Cognitive development and epistemology, pp. 151-235. , Mischel T, (ed), Academic Press; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Lee, I., Shin, Y.J., Machine learning for enterprises: Applications, algorithm selection, and challenges (2020) Business Horizons, 63 (2), pp. 157-170; Leicht-Deobald, U., Busch, T., Schank, C., Weibel, A., Schafheitle, S., Wildhaber, I., Kasper, G., The challenges of algorithm-based HR decision-making for personal integrity (2019) Journal of Business Ethics, 160 (2), pp. 377-392; Martin, K., Ethical implications and accountability of algorithms (2019) Journal of Business Ethics, 160 (4), pp. 835-850; Martin, K., Shilton, K., Smith, J., Business and the ethical implications of technology: Introduction to the symposium (2019) Journal of Business Ethics, 160 (2), pp. 307-317; Mitchell, M.S., Vogel, R.M., Folger, R., Third partiesâ€™ reactions to the abusive supervision of coworkers (2015) Journal of Applied Psychology, 100 (4), pp. 1040-1055; Mittelstadt, B., Principles alone cannot guarantee ethical AI (2019) Nature Machine Intelligence, 1 (11), pp. 501-507; Mooijman, M., Meindl, P., Oyserman, D., Monterosso, J., Dehghani, M., Doris, J.M., Graham, J., Resisting temptation for the good of the group: Binding moral values and the moralization of self-control (2018) Journal of Personality and Social Psychology, 115 (3), pp. 585-599; Morley, J., Floridi, L., Kinsey, L., Elhalal, A., From what to how: An initial review of publicly available AI ethics tools, methods and research to translate principles into practices (2020) Science and Engineering Ethics, 26 (4), pp. 2141-2168; Morse, L., Teodorescu, M.H.M., Awwad, Y., Kane, G.C., Do the ends justify the means? Variation in the distributive and procedural fairness of machine learning algorithms (2021) Journal of Business Ethics; Munoko, I., Brown-Liburd, H.L., Vasarhelyi, M., The ethical implications of using artificial intelligence in auditing (2020) Journal of Business Ethics, 167 (2), pp. 209-234; Murray, A., Rhymer, J., Sirmon, D.G., Humans and technology: Forms of conjoined agency in organizations (2021) Academy of Management Review, 46 (3), pp. 552-571; Neubert, M.J., MontaÃ±ez, G.D., Virtue as a framework for the design and use of artificial intelligence (2020) Business Horizons, 63 (2), pp. 195-204; Newman, D.T., Fast, N.J., Harmon, D.J., When eliminating bias isnâ€™t fair: Algorithmic reductionism and procedural justice in human resource decisions (2020) Organizational Behavior and Human Decision Processes, 160, pp. 149-167; Oâ€™Meara, S., Will China overtake the U.S. in artificial intelligence research? (2019) Scientific American, , https://www.scientificamerican.com/article/will-china-overtake-the-u-s-in-artificial-intelligence-research/, August 24, Retrieved from; Ouchi, W.G., The relationship between organizational structure and organizational control (1977) Administrative Science Quarterly, 22 (1), pp. 95-113; Porr, L., (2020) My GPT-3 Blog Got 26 Thousand Visitors in 2 Weeks, , https://liamp.substack.com/p/my-gpt-3-blog-got-26-thousand-visitors, Retrieved from; Raayoni, G., Gottlieb, S., Manor, Y., Pisha, G., Harris, Y., Mendlovic, U., Haviv, D., Kaminer, I., Generating conjectures on fundamental constants with the Ramanujan Machine (2021) Nature, 590 (7844), pp. 67-73; Rahim, M.A., Toward a theory of managing organizational conflict (2002) International Journal of Conflict Management, 13 (3), pp. 206-235; Rahwan, I., Society-in-the-loop: Programming the algorithmic social contract (2018) Ethics and Information Technology, 20 (1), pp. 5-14; Reynolds, S.J., Moral attentiveness: Who pays attention to the moral aspects of life? (2008) Journal of Applied Psychology, 93 (5), pp. 1027-1041; Seele, P., Dierksmeier, C., Hofstetter, R., Schultz, M.D., Mapping the ethicality of algorithmic pricing: A review of dynamic and personalized pricing (2021) Journal of Business Ethics, 170 (4), pp. 697-719; Shafer-Landau, R., (2014) The fundamentals of ethics, , 3, Oxford University Press; Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A., Lanctot, M., Hassabis, D., A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play (2018) Science, 362 (6419), pp. 1140-1144; Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Hassabis, D., Mastering the game of Go without human knowledge (2017) Nature, 550 (7676), pp. 354-359; Strubell, E., Ganesh, A., McCallum, A., Energy and policy considerations for deep learning in NLP (2019) Proceedings of the 57Th Annual Meeting of the Association for Computational Linguistics, pp. 3645-3650. , Florence, Italy; Vincent, J., OpenAIâ€™s latest breakthrough is astonishingly powerful, but still fighting its flaws (2020) The Verge, , https://www.theverge.com/21346343/gpt-3-explainer-openai-examples-errors-agi-potential, July 30; Wang, Y., Kosinski, M., Deep neural networks are more accurate than humans at detecting sexual orientation from facial images (2018) Journal of Personality and Social Psychology, 114 (2), pp. 246-257; Warren, D.E., Peytcheva, M., Gaspar, J.P., When ethical tones at the top conflict: Adapting priority rules to reconcile conflicting tones (2015) Business Ethics Quarterly, 25 (4), pp. 559-582; Waytz, A., Dungan, J., Young, L., The whistleblowerâ€™s dilemma and the fairnessâ€“loyalty tradeoff (2013) Journal of Experimental Social Psychology, 49 (6), pp. 1027-1033; Wright, S.A., Schultz, A.E., The rising tide of artificial intelligence and business automation: Developing an ethical framework (2018) Business Horizons, 61 (6), pp. 823-832; Yilmaz, O., Harma, M., BahÃ§ekapili, H.G., Cesur, S., Validation of the Moral Foundations Questionnaire in Turkey and its relation to cultural schemas of individualism and collectivism (2016) Personality and Individual Differences, 99, pp. 149-154; Zapko-Willmes, A., Schwartz, S.H., Richter, J., Kandler, C., Basic value orientations and moral foundations: Convergent or discriminant constructs? (2021) Journal of Research in Personality},
correspondence_address1={Telkamp, J.B.; Department of Management and Entrepreneurship, 2350 Gerdin Business Building, 2167 Union Drive, United States; email: jaketelk@iastate.edu},
editor={NA},
publisher={Springer Science and Business Media B.V.},
issn={01674544},
isbn={NA},
language={English},
abbrev_source_title={J. Bus. Ethics},
document_type={Article},
source={Scopus},
number={NA},
art_number={NA},
funding_details={NA},
coden={NA},
pubmed_id={NA},
sponsors={NA},
address={NA},
screened_abstracts={selected},
notes={NA},
}

@misc{WorldRob:online,
author = {World Robotics},
title = {World Robotics 2021 – Service Robots report released - International Federation of Robotics},
howpublished = {\url{https://ifr.org/ifr-press-releases/news/service-robots-hit-double-digit-growth-worldwide}},
month = {Nov},
year = {2021},
note = {(Accessed on 07/01/2022)}
}


%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Lauro Cesar Araujo at 2015-04-27 19:43:45 -0300 


%% Saved with string encoding Unicode (UTF-8) 



@book{ibge1993,
  address       = {Rio de Janeiro},
  author        = {IBGE},
  date-added    = {2013-08-21 13:56:10 +0000},
  date-modified = {2013-08-21 13:56:10 +0000},
  edition       = {3},
  organization  = {http://biblioteca.ibge.gov.br/visualizacao/livros/liv23907.pdf},
  publisher     = {Centro de Documenta{\c c}{\~a}o e Dissemina{\c c}{\~a}o de Informa{\c c}{\~o}es. Funda{\c c}{\~a}o Intituto Brasileiro de Geografia e Estat{\'\i}stica},
  title         = {Normas de apresenta{\c c}{\~a}o tabular},
  urlaccessdate = {21 ago 2013},
  year          = {1993}
}

@misc{abntex2-wiki-como-customizar,
  author        = {Lauro C{\'e}sar Araujo},
  date-added    = {2013-03-23 21:39:21 +0000},
  date-modified = {2015-04-27 22:43:06 +0000},
  howpublished  = {Wiki do abnTeX2},
  keywords      = {wiki},
  title         = {Como customizar o abnTeX2},
  url           = {https://github.com/abntex/abntex2/wiki/ComoCustomizar},
  urlaccessdate = {27 abr 2015},
  year          = {2015},
  bdsk-url-1    = {https://github.com/abntex/abntex2/wiki/ComoCustomizar}
}

@manual{talbot2012,
  author        = {Nicola L.C. Talbot},
  date-added    = {2013-03-11 12:06:04 +0000},
  date-modified = {2013-03-11 12:06:56 +0000},
  month         = {Nov.},
  title         = {User Manual for glossaries.sty},
  url           = {http://mirrors.ctan.org/macros/latex/contrib/glossaries/glossaries-user.pdf},
  urlaccessdate = {11 mar. 2013},
  year          = {2012},
  bdsk-url-1    = {http://mirrors.ctan.org/macros/latex/contrib/glossaries/glossaries-user.pdf}
}

@manual{babel,
  author        = {Johannes Braams},
  date-added    = {2013-02-17 13:37:14 +0000},
  date-modified = {2013-02-17 13:38:38 +0000},
  month         = {Apr.},
  title         = {Babel, a multilingual package for use with LATEX's standard document classes},
  url           = {http://mirrors.ctan.org/info/babel/babel.pdf},
  urlaccessdate = {17 fev. 2013},
  year          = {2008},
  bdsk-url-1    = {http://mirrors.ctan.org/info/babel/babel.pdf}
}

@manual{abntex2modelo-artigo,
  annote        = {Este documento {\'e} derivado do \cite{abnt-bibtex-doc}},
  author        = {Lauro C{\'e}sar Araujo},
  date-added    = {2013-01-15 00:10:35 +0000},
  date-modified = {2015-04-27 22:43:13 +0000},
  organization  = {Equipe abnTeX2},
  title         = {Modelo Can{\^o}nico de Artigo Cient{\'\i}fico com abnTeX2},
  url           = {http://www.abntex.net.br/},
  year          = {2015},
  bdsk-url-1    = {http://www.abntex.net.br/}
}

@manual{abntex2modelo-relatorio,
  annote        = {Este documento {\'e} derivado do \cite{abnt-bibtex-doc}},
  author        = {Lauro C{\'e}sar Araujo},
  date-added    = {2013-01-15 00:05:34 +0000},
  date-modified = {2015-04-27 22:43:18 +0000},
  organization  = {Equipe abnTeX2},
  title         = {Modelo Can{\^o}nico de Relat{\'o}rio T{\'e}cnico e/ou Cient{\'\i}fico com abnTeX2},
  url           = {http://www.abntex.net.br/},
  year          = {2015},
  bdsk-url-1    = {http://www.abntex.net.br/}
}

@manual{abntex2modelo,
  annote        = {Este documento {\'e} derivado do \cite{abnt-bibtex-doc}},
  author        = {Lauro C{\'e}sar Araujo},
  date-added    = {2013-01-12 22:55:32 +0000},
  date-modified = {2015-04-27 22:43:32 +0000},
  organization  = {Equipe abnTeX2},
  title         = {Modelo Can{\^o}nico de Trabalho Acad{\^e}mico com abnTeX2},
  url           = {http://www.abntex.net.br/},
  year          = {2015},
  bdsk-url-1    = {http://www.abntex.net.br/}
}

@mastersthesis{araujo2012,
  address       = {Bras{\'\i}lia},
  author        = {Lauro C{\'e}sar Araujo},
  date-added    = {2013-01-09 11:04:42 +0000},
  date-modified = {2013-01-09 11:04:42 +0000},
  month         = {mar.},
  school        = {Universidade de Bras{\'\i}lia},
  subtitle      = {uma perspectiva de {A}rquitetura da {I}nforma{\c c}{\~a}o da {E}scola de {B}ras{\'\i}lia},
  title         = {Configura{\c c}{\~a}o},
  year          = {2012}
}

@manual{memoir,
  address       = {Normandy Park, WA},
  author        = {Peter Wilson and Lars Madsen},
  date-added    = {2013-01-09 10:37:50 +0000},
  date-modified = {2013-03-21 13:23:25 +0000},
  organization  = {The Herries Press},
  title         = {The Memoir Class for Configurable Typesetting - User Guide},
  url           = {http://mirrors.ctan.org/macros/latex/contrib/memoir/memman.pdf},
  urlaccessdate = {19 dez. 2012},
  year          = {2010},
  bdsk-url-1    = {http://ctan.tche.br/macros/latex/contrib/memoir/memman.pdf}
}

@manual{abntex2cite-alf,
  annote        = {Este documento {\'e} derivado do \cite{abnt-bibtex-alf-doc}},
  author        = {Lauro C{\'e}sar Araujo},
  date-added    = {2013-01-09 10:37:45 +0000},
  date-modified = {2015-04-27 22:43:44 +0000},
  organization  = {Equipe abnTeX2},
  title         = {O pacote abntex2cite: t{\'o}picos espec{\'\i}ficos da ABNT NBR 10520:2002 e o estilo bibliogr{\'a}fico alfab{\'e}tico (sistema autor-data)},
  url           = {http://www.abntex.net.br/},
  year          = {2015},
  bdsk-url-1    = {http://www.abntex.net.br/}
}

@manual{abntex2cite,
  annote        = {Este documento {\'e} derivado do \cite{abnt-bibtex-doc}},
  author        = {Lauro C{\'e}sar Araujo},
  date-added    = {2013-01-09 10:37:45 +0000},
  date-modified = {2015-04-27 22:43:38 +0000},
  organization  = {Equipe abnTeX2},
  title         = {O pacote abntex2cite: Estilos bibliogr{\'a}ficos compat{\'\i}veis com a ABNT NBR 6023},
  url           = {http://www.abntex.net.br/},
  year          = {2015},
  bdsk-url-1    = {http://www.abntex.net.br/}
}

@manual{abntex2classe,
  author        = {Lauro C{\'e}sar Araujo},
  date-added    = {2013-01-09 10:37:38 +0000},
  date-modified = {2015-04-27 22:42:47 +0000},
  organization  = {Equipe abnTeX2},
  title         = {A classe abntex2: Modelo can{\^o}nico de trabalhos acad{\^e}micos brasileiros compat{\'\i}vel com as normas ABNT NBR 14724:2011, ABNT NBR 6024:2012 e outras},
  url           = {http://www.abntex.net.br/},
  year          = {2015},
  bdsk-url-1    = {http://www.abntex.net.br/}
}

@manual{NBR10520:2002,
  address       = {Rio de Janeiro},
  date-added    = {2012-12-15 21:43:38 +0000},
  date-modified = {2013-01-12 22:17:20 +0000},
  month         = {ago.},
  org-short     = {ABNT},
  organization  = {Associa{\c c}\~ao Brasileira de Normas T\'ecnicas},
  pages         = 7,
  subtitle      = {Informa{\c c}\~ao e documenta{\c c}\~ao --- Apresenta{\c c}\~ao de cita{\c c}\~oes em documentos},
  title         = {{NBR} 10520},
  year          = 2002
}

@manual{NBR6024:2012,
  address       = {Rio de Janeiro},
  date-added    = {2012-12-15 21:24:06 +0000},
  date-modified = {2012-12-15 21:24:28 +0000},
  month         = {fev.},
  org-short     = {ABNT},
  organization  = {Associa{\c c}\~ao Brasileira de Normas T\'ecnicas},
  pages         = 4,
  subtitle      = {Numera{\c c}\~ao progressiva das se{\c c}\~oes de um documento},
  title         = {{NBR} 6024},
  year          = 2012
}

@manual{NBR6028:2003,
  address       = {Rio de Janeiro},
  date-added    = {2012-12-15 21:02:12 +0000},
  date-modified = {2012-12-15 21:02:50 +0000},
  month         = {nov.},
  org-short     = {ABNT},
  organization  = {Associa{\c c}\~ao Brasileira de Normas T\'ecnicas},
  pages         = 2,
  subtitle      = {Resumo - Apresenta{\c c}{\~a}o},
  title         = {{NBR} 6028},
  year          = 2003
}

@manual{NBR14724:2001,
  address       = {Rio de Janeiro},
  date-added    = {2012-12-15 20:34:08 +0000},
  date-modified = {2012-12-15 20:34:08 +0000},
  month         = {jul.},
  org-short     = {ABNT},
  organization  = {Associa{\c c}\~ao Brasileira de Normas T\'ecnicas},
  pages         = 6,
  subtitle      = {Informa{\c c}\~ao e documenta{\c c}\~ao --- trabalhos acad\^emicos --- apresenta{\c c}\~ao},
  title         = {{NBR} 14724},
  year          = 2001
}

@manual{NBR14724:2002,
  address       = {Rio de Janeiro},
  date-added    = {2012-12-15 20:34:17 +0000},
  date-modified = {2012-12-15 20:34:17 +0000},
  month         = {ago.},
  org-short     = {ABNT},
  organization  = {Associa{\c c}\~ao Brasileira de Normas T\'ecnicas},
  pages         = 6,
  subtitle      = {Informa{\c c}\~ao e documenta{\c c}\~ao --- trabalhos acad\^emicos --- apresenta{\c c}\~ao},
  title         = {{NBR} 14724},
  year          = 2002
}

@manual{NBR14724:2005,
  address       = {Rio de Janeiro},
  date-added    = {2012-12-15 20:34:08 +0000},
  date-modified = {2012-12-15 20:35:25 +0000},
  month         = {dez.},
  org-short     = {ABNT},
  organization  = {Associa{\c c}\~ao Brasileira de Normas T\'ecnicas},
  pages         = 9,
  subtitle      = {Informa{\c c}\~ao e documenta{\c c}\~ao --- trabalhos acad\^emicos --- apresenta{\c c}\~ao},
  title         = {{NBR} 14724},
  year          = 2005
}

@manual{NBR14724:2011,
  address       = {Rio de Janeiro},
  date-added    = {2012-12-15 20:34:08 +0000},
  date-modified = {2012-12-15 20:35:25 +0000},
  month         = {mar.},
  note          = {Substitui a Ref.~\citeonline{NBR14724:2005}},
  org-short     = {ABNT},
  organization  = {Associa{\c c}\~ao Brasileira de Normas T\'ecnicas},
  pages         = 15,
  subtitle      = {Informa{\c c}\~ao e documenta{\c c}\~ao --- trabalhos acad\^emicos --- apresenta{\c c}\~ao},
  title         = {{NBR} 14724},
  year          = 2011
}

@article{van86,
  author  = {{van}, Gigch, John P. and Leo L. Pipino},
  journal = {Future Computing Systems},
  number  = {1},
  pages   = {71-97},
  title   = {In search for a paradigm for the discipline of information systems},
  volume  = {1},
  year    = {1986}
}

@phdthesis{guizzardi2005,
  address       = {Enschede, The Netherlands},
  author        = {Giancarlo Guizzardi},
  date-added    = {2012-04-23 11:35:28 +0000},
  date-modified = {2012-04-23 11:35:28 +0000},
  school        = {Centre for Telematics and Information Technology, University of Twente},
  title         = {Ontological Foundations for Structural Conceptual Models},
  url           = {http://www.loa.istc.cnr.it/Guizzardi/SELMAS-CR.pdf},
  urlaccessdate = {3 jul. 2011},
  year          = {2005},
  bdsk-url-1    = {http://www.loa.istc.cnr.it/Guizzardi/SELMAS-CR.pdf}
}

@mastersthesis{macedo2005,
  author        = {Fl{\'a}via L. Macedo},
  date-added    = {2012-04-23 11:35:13 +0000},
  date-modified = {2012-04-23 11:35:13 +0000},
  keywords      = {arquitetura da informa{\c c}{\~a}o},
  school        = {Universidade de Bras{\'\i}lia},
  title         = {Arquitetura da Informa{\c c}{\~a}o: aspectos espistemol{\'o}gicos, cient{\'\i}ficos e pr{\'a}ticos.},
  type          = {Disserta{\c c}{\~a}o de Mestrado},
  year          = {2005}
}

@manual{EIA649B,
  address       = {EUA},
  date-added    = {2012-04-23 11:34:59 +0000},
  date-modified = {2012-04-23 11:34:59 +0000},
  keywords      = {norma},
  month         = {June},
  organization  = {TechAmerica},
  title         = {ANSI/EIA 649-B: Configuration Management Standard},
  year          = {2011}
}

@inproceedings{masolo2010,
  author        = {Claudio Masolo},
  booktitle     = {Proceedings of the Twelfth International Conference on the Principles of Knowledge Representation and Reasoning (KR 2010)},
  date-added    = {2012-04-23 11:34:38 +0000},
  date-modified = {2012-04-23 11:34:38 +0000},
  editor        = {Lin, F. and Sattler, U.},
  pages         = {258-268},
  publisher     = {AAAI Press},
  title         = {Understanding Ontological Levels},
  url           = {http://wiki.loa-cnr.it/Papers/kr10v0.7.pdf},
  urlaccessdate = {2 jan. 2012},
  year          = {2010},
  bdsk-url-1    = {http://wiki.loa-cnr.it/Papers/kr10v0.7.pdf}
}

@inbook{guarino1995,
  address       = {Vienna},
  author        = {Nicola Guarino},
  booktitle     = {Philosophy and the Cognitive Science},
  date-added    = {2012-04-23 11:34:29 +0000},
  date-modified = {2012-04-23 11:34:29 +0000},
  editor        = {R. Casati and B. Smith and G. White},
  month         = {Sept.},
  pages         = {443-456},
  publisher     = {Holder-Pivhler-Tempsky},
  title         = {The Ontological Level},
  url           = {http://wiki.loa-cnr.it/Papers/OntLev.pdf},
  urlaccessdate = {2 jan. 2012},
  year          = {1995},
  bdsk-url-1    = {http://wiki.loa-cnr.it/Papers/OntLev.pdf}
}

@incollection{bates2010,
  address       = {New York},
  author        = {Marcia J. Bates},
  booktitle     = {Encyclopedia of Library and Information Sciences},
  date-added    = {2012-04-23 11:34:29 +0000},
  date-modified = {2012-04-23 11:34:29 +0000},
  edition       = {3rd},
  editor        = {Marcia J. Bates and Mary Niles Maack},
  pages         = {2347-2360},
  publisher     = {CRC Press},
  title         = {Information},
  url           = {http://pages.gseis.ucla.edu/faculty/bates/articles/information.html},
  urlaccessdate = {24 out. 2011},
  volume        = {3},
  year          = {2010},
  bdsk-url-1    = {http://pages.gseis.ucla.edu/faculty/bates/articles/information.html}
}

@book{doxiadis1965,
  author        = {Constantinos A. Doxiadis},
  date-added    = {2012-04-23 11:34:20 +0000},
  date-modified = {2012-04-23 11:34:20 +0000},
  publisher     = {Ceira - Coimbra},
  title         = {Arquitetura em Transi{\c c}{\~a}o},
  year          = {1965}
}

@book{dewey1980,
  address       = {New York, NY, USA},
  author        = {John Dewey},
  date-added    = {2012-04-23 11:34:16 +0000},
  date-modified = {2012-04-23 11:34:16 +0000},
  publisher     = {Perigee Books},
  title         = {Art as Experience},
  year          = {1980}
}

